{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for startup\n",
    "BasicLink1=\"http://www.canada411.ca/search/si/\"\n",
    "PageNumber=0\n",
    "BasicLink2=\"/\"\n",
    "BasicLink3=\"/Canada/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Names from client's file\n",
    "with open('names.txt', 'r') as myfile:\n",
    "    data=myfile.read()\n",
    "all_names=data.split(\",\")\n",
    "\n",
    "len(all_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Scrapping Total number of names for a specific name from first page\n",
    "def GetNumberofNames(name):\n",
    "    no_name=True\n",
    "    link=\"\"\n",
    "    NumberOfNames=0\n",
    "    try:\n",
    "        link=BasicLink1 + str(1) + BasicLink2 + name + BasicLink3\n",
    "        r=requests.get(link)\n",
    "        soup=BeautifulSoup(r.text,'html.parser')\n",
    "        resultstop= soup.find_all('div',attrs={'class':'c411ResultsTop'})\n",
    "        fr = resultstop[0]\n",
    "        x = fr.find(\"h1\").text\n",
    "        y = x.split(\" \")\n",
    "        NumberOfNames = y[0]\n",
    "        NumberOfNames=NumberOfNames.replace(\",\",\"\")\n",
    "        NumberOfNames=int(NumberOfNames)\n",
    "        no_name=False\n",
    "    except:\n",
    "        NumberOfNames=0\n",
    "        no_name=True\n",
    "    return NumberOfNames,no_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Writing in 2 seperate files, \"ALL Names.txt\" has all names and \"ALL Contact Numbers.txt\" has all contact numbers \n",
    "def WriteInFile(Names,ContactNumbers,NumberOfNames):\n",
    "    file=open(\"ALL Names.txt\",\"a\")\n",
    "    file2=open(\"ALL Contact Numbers.txt\",\"a\")\n",
    "    for i in range(NumberOfNames):\n",
    "        file.write(Names[i])\n",
    "        file.write(\"\\n\")\n",
    "        file2.write(ContactNumbers[i])\n",
    "        file2.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_time and end_time , total_time : to calculate execution time\n",
    "#All_names_Done: Number of names done in total\n",
    "#Names_fetched_for_this_name: number of names fetched for one name\n",
    "#all_names: all names to be searched \n",
    "start_time = datetime.datetime.now().time().strftime('%H:%M:%S')\n",
    "\n",
    "All_names_Done=0\n",
    "Names_fetched=0\n",
    "Names_fetched_for_this_name=0\n",
    "for name in all_names: \n",
    "    start_time2 = datetime.datetime.now().time().strftime('%H:%M:%S')\n",
    "    number_fetch_bool=False\n",
    "    NumberOfNames,no_name=GetNumberofNames(name)\n",
    "    PageNumber=0\n",
    "    Scrapped_Names = []\n",
    "    Scrapped_ContactNumbers=[]\n",
    "    Done=0\n",
    "    j=0\n",
    "    Names_fetched_for_this_name=0\n",
    "    if no_name==False:\n",
    "        for i in range(NumberOfNames):\n",
    "            if Done%15==0:\n",
    "                PageNumber+=1\n",
    "                link=BasicLink1 + str(PageNumber) + BasicLink2 + name+ BasicLink3\n",
    "                r=requests.get(link)\n",
    "                soup=BeautifulSoup(r.text,'html.parser')\n",
    "                ContactList= soup.find_all('span',attrs={'class':'c411Phone'})\n",
    "                NamesList  = soup.find_all('h2',attrs={'class':'c411ListedName'})\n",
    "                j=0\n",
    "            Scrapped_Names.append(NamesList[j].text)\n",
    "            Scrapped_ContactNumbers.append(ContactList[j].text)\n",
    "            Done+=1\n",
    "            j+=1\n",
    "            Names_fetched+=1\n",
    "            Names_fetched_for_this_name+=1\n",
    "        All_names_Done+=1\n",
    "        WriteInFile(Scrapped_Names,Scrapped_ContactNumbers,NumberOfNames)\n",
    "\n",
    "        if NumberOfNames==Names_fetched_for_this_name:\n",
    "            number_fetch_bool=True            \n",
    "        print(All_names_Done,\"\\t\", NumberOfNames ,\"\\t\", Names_fetched_for_this_name , \"\\t\" , number_fetch_bool , \"\\t\" ,Names_fetched , \"\\t\" , name, \"\\t\")\n",
    "end_time = datetime.datetime.now().time().strftime('%H:%M:%S')\n",
    "total_time=(datetime.datetime.strptime(end_time,'%H:%M:%S') - datetime.datetime.strptime(start_time,'%H:%M:%S'))\n",
    "print(total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
